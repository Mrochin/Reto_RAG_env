{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a866c3c5",
   "metadata": {},
   "source": [
    "m# RETO RAG — Implementación End-to-End (Paso 3)\n",
    "\n",
    "Este notebook implementa un **sistema RAG (Retrieval-Augmented Generation)** en entorno local (Anaconda + PyCharm).\n",
    "Incluye: ingestión de PDF, chunking, embeddings, base vectorial **ChromaDB**, y pipeline de Recuperación + Generación.\n",
    "\n",
    "**Requisitos mínimos**: `pip install --no-cache-dir langchain langchain-openai chromadb pypdf`\n",
    "(Opcionales: `tiktoken`, `papermill`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9027cc5c",
   "metadata": {},
   "source": [
    "## 0) Configuración inicial"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T23:43:56.296462Z",
     "start_time": "2025-09-16T23:43:56.227668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables desde .env\n",
    "load_dotenv()\n",
    "\n",
    "# Verificar que está cargada\n",
    "print(\"API Key presente:\", \"OPENAI_API_KEY\" in os.environ)"
   ],
   "id": "35fc0f9d9e42360",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key presente: True\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8eb8c0d8df896ea8"
  },
  {
   "cell_type": "code",
   "id": "e68c903e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T23:44:04.675951Z",
     "start_time": "2025-09-16T23:44:04.667496Z"
    }
   },
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "PDFS_DIR = Path(\"docs\")\n",
    "PDF_FILE = PDFS_DIR / \"ejemplo.pdf\"\n",
    "CHROMA_PERSIST_DIR = Path(\"./.chroma_db_local\")\n",
    "\n",
    "OPENAI_EMBED_MODEL = \"text-embedding-3-small\"\n",
    "OPENAI_CHAT_MODEL  = \"gpt-4o-mini\"\n",
    "\n",
    "PDFS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "CHROMA_PERSIST_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"OPENAI_API_KEY presente:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY presente: True\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "2eacb7d2",
   "metadata": {},
   "source": [
    "## 1) Ingesta de PDF → Texto"
   ]
  },
  {
   "cell_type": "code",
   "id": "acafd3aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T22:24:12.489066Z",
     "start_time": "2025-09-16T22:24:00.482692Z"
    }
   },
   "source": [
    "\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    reader = PdfReader(str(pdf_path))\n",
    "    return \"\\n\".join([p.extract_text() or \"\" for p in reader.pages])\n",
    "\n",
    "if PDF_FILE.exists():\n",
    "    raw_text = extract_text_from_pdf(PDF_FILE)\n",
    "    print(\"Longitud del texto extraído:\", len(raw_text))\n",
    "else:\n",
    "    raw_text = \"\"\n",
    "    print(f\"Coloca un PDF en {PDF_FILE} y vuelve a ejecutar esta celda.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto extraído: 73876\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "78bd61b7",
   "metadata": {},
   "source": [
    "## 2) Chunking"
   ]
  },
  {
   "cell_type": "code",
   "id": "6eecf184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T22:24:48.496158Z",
     "start_time": "2025-09-16T22:24:48.484428Z"
    }
   },
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_text(text: str, chunk_size=500, chunk_overlap=80):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        length_function=len,\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "chunks = chunk_text(raw_text) if raw_text else []\n",
    "print(f\"Total de fragmentos: {len(chunks)}\")\n",
    "if chunks[:1]:\n",
    "    print(\"Ejemplo de fragmento:\\n\", chunks[0][:200], \"...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de fragmentos: 189\n",
      "Ejemplo de fragmento:\n",
      " I n n o v a c i ó n  y  m e j o r a  C o n t i n u aG e s t i ó n  I n t e g r a l  d e  I n v e n t a r i o s   “ s y n c F l o w ”\n",
      "G e s t i ó n  I n t e g r a l  D e  \n",
      "I n v e n t a r i o s\n",
      "S y n c ...\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "11af27ad",
   "metadata": {},
   "source": [
    "## 3) Embeddings + ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "id": "0cdbb4e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T22:26:36.326811Z",
     "start_time": "2025-09-16T22:26:33.807746Z"
    }
   },
   "source": [
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "def build_vector_store(text_chunks, persist_dir: Path):\n",
    "    if not text_chunks:\n",
    "        raise ValueError(\"No hay fragmentos para indexar. Verifica el PDF y el chunking.\")\n",
    "    emb = OpenAIEmbeddings(model=OPENAI_EMBED_MODEL)\n",
    "    # Al crear con persist_directory, Chroma persiste automáticamente (>=0.4)\n",
    "    db = Chroma.from_texts(text_chunks, emb, persist_directory=str(persist_dir))\n",
    "    return db\n",
    "\n",
    "db = None\n",
    "if chunks:\n",
    "    db = build_vector_store(chunks, CHROMA_PERSIST_DIR)\n",
    "    print(\"ChromaDB inicializada en:\", CHROMA_PERSIST_DIR)\n",
    "else:\n",
    "    print(\"No se construyó la base vectorial (sin fragmentos).\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB inicializada en: .chroma_db_local\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "b74c6e48",
   "metadata": {},
   "source": [
    "## 4) Recuperación + Generación"
   ]
  },
  {
   "cell_type": "code",
   "id": "c22ee5ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T22:27:12.906880Z",
     "start_time": "2025-09-16T22:27:12.755498Z"
    }
   },
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def build_rag_chain(chroma_db, chat_model=OPENAI_CHAT_MODEL, k=4):\n",
    "    llm = ChatOpenAI(model=chat_model)\n",
    "    retriever = chroma_db.as_retriever(search_kwargs={\"k\": k})\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm, retriever=retriever, return_source_documents=True\n",
    "    )\n",
    "    return qa\n",
    "\n",
    "qa = build_rag_chain(db) if db else None\n",
    "if qa: print(\"Pipeline RAG listo.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline RAG listo.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "3ba6ce3f",
   "metadata": {},
   "source": [
    "## 5) Prueba rápida"
   ]
  },
  {
   "cell_type": "code",
   "id": "d5224780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T22:27:29.496571Z",
     "start_time": "2025-09-16T22:27:24.474896Z"
    }
   },
   "source": [
    "\n",
    "query = \"¿Cuáles son los conceptos clave mencionados en el documento?\"\n",
    "if qa and os.getenv(\"OPENAI_API_KEY\"):\n",
    "    result = qa.invoke({\"query\": query})\n",
    "    print(\"Respuesta:\", result[\"result\"])\n",
    "    print(\"\\n---\\nFragmentos usados:\")\n",
    "    for i, doc in enumerate(result[\"source_documents\"], start=1):\n",
    "        print(f\"[{i}] {doc.page_content[:200]}...\")\n",
    "elif qa and not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Configura OPENAI_API_KEY antes de consultar.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: Los conceptos clave mencionados en el documento son:\n",
      "\n",
      "1. Aplicar políticas detectadas\n",
      "2. Descartar registros\n",
      "3. Descartar productos con ciertos estados (Terminación, No Definido)\n",
      "4. Descartar productos marcados como \"avoid replenishment\"\n",
      "5. Reglas de administración de catálogo\n",
      "6. Administrar catálogo\n",
      "7. Categorización según propósito\n",
      "8. Listado de productos\n",
      "9. Pronósticos de ventas\n",
      "10. Distribución de inventario\n",
      "11. Cálculo de tamaños\n",
      "12. Participación en catálogo\n",
      "13. Distribución de catálogo\n",
      "\n",
      "---\n",
      "Fragmentos usados:\n",
      "[1] A p l i c a r  l a s  p o l i t i c a s  d e t e c t a d a s\n",
      "D e s c a r t a r  p o r  n o  c o n t a r  c o n  i n v e n t a r i o  i n i c i a l ,  e n t r a d a s ,  s a l i d a s  y  \n",
      "v e n t a s\n",
      "...\n",
      "[2] A p l i c a r  l a s  p o l i t i c a s  d e t e c t a d a s\n",
      "D e s c a r t a r  p o r  n o  c o n t a r  c o n  i n v e n t a r i o  i n i c i a l ,  e n t r a d a s ,  s a l i d a s  y  \n",
      "v e n t a s\n",
      "...\n",
      "[3] ✓ R e g l a s  d e  a d m i n i s t r a c i ó n  d e  \n",
      "c a t á l o g o\n",
      "✓ A d m i n i s t r a r  c a t á l o g o\n",
      "✓ C a t e g o r i z a c i ó n  s e g u n  p r o p ó s i t o\n",
      "✓ L i s t a d o  d e  p r o ...\n",
      "[4] ✓ R e g l a s  d e  a d m i n i s t r a c i ó n  d e  \n",
      "c a t á l o g o\n",
      "✓ A d m i n i s t r a r  c a t á l o g o\n",
      "✓ C a t e g o r i z a c i ó n  s e g u n  p r o p ó s i t o\n",
      "✓ L i s t a d o  d e  p r o ...\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T22:29:37.096283Z",
     "start_time": "2025-09-16T22:29:35.560639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"¿De que trata el concepto hsbt?\"\n",
    "if qa and os.getenv(\"OPENAI_API_KEY\"):\n",
    "    result = qa.invoke({\"query\": query})\n",
    "    print(\"Respuesta:\", result[\"result\"])\n",
    "    print(\"\\n---\\nFragmentos usados:\")\n",
    "    for i, doc in enumerate(result[\"source_documents\"], start=1):\n",
    "        print(f\"[{i}] {doc.page_content[:200]}...\")\n",
    "elif qa and not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Configura OPENAI_API_KEY antes de consultar.\")\n"
   ],
   "id": "2a285e52a99d5c5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: No sé.\n",
      "\n",
      "---\n",
      "Fragmentos usados:\n",
      "[1] R e g l a s  p a r a  e l  c á l c u l o  d e  H S B T\n",
      "E s  l a  c l a s i f i c a c i ó n  q u e  s e  l e s  d a  a  l o s  p r o d u c t o s  d e  a c u e r d o  a  s u  p a r t i c i p a c i ó n  ...\n",
      "[2] R e g l a s  p a r a  e l  c á l c u l o  d e  H S B T\n",
      "E s  l a  c l a s i f i c a c i ó n  q u e  s e  l e s  d a  a  l o s  p r o d u c t o s  d e  a c u e r d o  a  s u  p a r t i c i p a c i ó n  ...\n",
      "[3] R e g l a s  p a r a  e l  c á l c u l o  d e  H S B T\n",
      "E s  l a  c a n t i d a d  d e  i n v e n t a r i o  c o n s u m i d o  e n  r e f e r e n c i a  a l  b u f f e r ,  e s  d e c i r ,  u n a  p ...\n",
      "[4] R e g l a s  p a r a  e l  c á l c u l o  d e  H S B T\n",
      "E s  l a  c a n t i d a d  d e  i n v e n t a r i o  c o n s u m i d o  e n  r e f e r e n c i a  a l  b u f f e r ,  e s  d e c i r ,  u n a  p ...\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T22:30:42.422505Z",
     "start_time": "2025-09-16T22:30:38.084337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"¿Regla para el cálculo de Hsbt?\"\n",
    "if qa and os.getenv(\"OPENAI_API_KEY\"):\n",
    "    result = qa.invoke({\"query\": query})\n",
    "    print(\"Respuesta:\", result[\"result\"])\n",
    "    print(\"\\n---\\nFragmentos usados:\")\n",
    "    for i, doc in enumerate(result[\"source_documents\"], start=1):\n",
    "        print(f\"[{i}] {doc.page_content[:200]}...\")\n",
    "elif qa and not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Configura OPENAI_API_KEY antes de consultar.\")"
   ],
   "id": "5e56c08bf25fa912",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: La regla para el cálculo de Hsbt es una clasificación que se les da a los productos de acuerdo a su participación en la venta. Puede ser calculado a nivel catálogo, segmento o familia, según el lugar donde se consulta. Además, se menciona que la penetración indica la cantidad de inventario consumido en referencia al buffer, donde una penetración de 100% indica que todo el inventario se ha agotado y una penetración de 10% indica que tienes el 90% de inventario disponible.\n",
      "\n",
      "---\n",
      "Fragmentos usados:\n",
      "[1] R e g l a s  p a r a  e l  c á l c u l o  d e  H S B T\n",
      "E s  l a  c l a s i f i c a c i ó n  q u e  s e  l e s  d a  a  l o s  p r o d u c t o s  d e  a c u e r d o  a  s u  p a r t i c i p a c i ó n  ...\n",
      "[2] R e g l a s  p a r a  e l  c á l c u l o  d e  H S B T\n",
      "E s  l a  c l a s i f i c a c i ó n  q u e  s e  l e s  d a  a  l o s  p r o d u c t o s  d e  a c u e r d o  a  s u  p a r t i c i p a c i ó n  ...\n",
      "[3] R e g l a s  p a r a  e l  c á l c u l o  d e  H S B T\n",
      "E s  l a  c a n t i d a d  d e  i n v e n t a r i o  c o n s u m i d o  e n  r e f e r e n c i a  a l  b u f f e r ,  e s  d e c i r ,  u n a  p ...\n",
      "[4] R e g l a s  p a r a  e l  c á l c u l o  d e  H S B T\n",
      "E s  l a  c a n t i d a d  d e  i n v e n t a r i o  c o n s u m i d o  e n  r e f e r e n c i a  a l  b u f f e r ,  e s  d e c i r ,  u n a  p ...\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
